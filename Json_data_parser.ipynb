{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1  a) parse the following JSON data stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-[ ] are for JSON arrays, which are called list in Python\n",
    "- { } are for JSON objects, which are called dict in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data is not in the correct json format, example, having single quotes instead of double quotes and is also having\n",
    "# some other special characters. Replacing them and saving the file in correct format which can be parsed.\n",
    "\n",
    "\n",
    "import json\n",
    "import ast\n",
    "import io\n",
    "f = io.open(\"ff.txt\",'r',encoding='utf-8')\n",
    "lines = f.readlines()\n",
    "# print(lines)\n",
    "f.close()\n",
    "lines = [line.replace(\"'\", '\"').replace('‘', '\"').replace(' \"', '\"').replace('’', '\"').replace('\\n', ' ').replace('\" ', '\",') for line in lines]\n",
    "# print (lines)\n",
    "\n",
    "newLines = ''\n",
    "for line in lines:\n",
    "    newLines += str(line.strip('\\n'))\n",
    "\n",
    "f = io.open(\"ff2.txt\",'w',encoding='utf-8')\n",
    "f.write(u\"%s\" %(lines))\n",
    "f.close()\n",
    "\n",
    "jsonData = ast.literal_eval(newLines) #to convert text to meaningful expression\n",
    "\n",
    "\n",
    "finaldata = {}\n",
    "for i in range(len(jsonData)):\n",
    "    finaldata[str(i)] = jsonData[i]\n",
    "\n",
    "with io.open(\"final.json\", 'w', encoding='utf8') as json_file:\n",
    "    data = json.dumps(finaldata, ensure_ascii=False)\n",
    "    json_file.write(u\"%s\" %(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Donna Summer',\n",
       "  'updated': '2016-02-26T09:09:37',\n",
       "  'recommendations': ['I worked with Donna for 5 years and can highly recommend her as an experienced, knowledgeable. She is very hardworking designer with a meticulous eye for detail and creativity',\n",
       "   'I have worked with Donna for a number of years and have always found her to be extremely professional and a real expert in her field.',\n",
       "   'Donna is always on the ball, highly organised and a real pleasure to work with.']},\n",
       " {'name': 'Justin Bieber',\n",
       "  'updated': '2016-02-26T09:09:37',\n",
       "  'recommendations': ['Justin is a consummate professional and a pleasure to work with at all times!']}]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Donna Summer',\n",
       " 'updated': '2016-02-26T09:09:37',\n",
       " 'recommendations': ['I worked with Donna for 5 years and can highly recommend her as an experienced, knowledgeable. She is very hardworking designer with a meticulous eye for detail and creativity',\n",
       "  'I have worked with Donna for a number of years and have always found her to be extremely professional and a real expert in her field.',\n",
       "  'Donna is always on the ball, highly organised and a real pleasure to work with.']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I worked with Donna for 5 years and can highly recommend her as an experienced, knowledgeable. She is very hardworking designer with a meticulous eye for detail and creativity',\n",
       " 'I have worked with Donna for a number of years and have always found her to be extremely professional and a real expert in her field.',\n",
       " 'Donna is always on the ball, highly organised and a real pleasure to work with.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData[0][\"recommendations\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Donna is always on the ball, highly organised and a real pleasure to work with.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData[0][\"recommendations\"][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Justin Bieber'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData[1][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Justin is a consummate professional and a pleasure to work with at all times!']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jsonData[1][\"recommendations\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) create an LDA, or other model of your choice, for the review data, and\n",
    "##  c) convert the reviews into feature vectors using the model that you built.\n",
    "\n",
    "### Combined Solutions below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bag of words model is implemented.\n",
    "# importing the packages for this part\n",
    "import re, nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer        \n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "def stem_tokens(tokens, stemmer):\n",
    "    stemmed = []\n",
    "    for item in tokens:\n",
    "        stemmed.append(stemmer.stem(item))\n",
    "    return stemmed\n",
    "\n",
    "def tokenize(text):\n",
    "    # remove non letters\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", text)\n",
    "    # tokenize\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    # stem\n",
    "    stems = stem_tokens(tokens, stemmer)\n",
    "    return stems\n",
    "\n",
    "vectorizer = CountVectorizer(\n",
    "    analyzer = 'word',\n",
    "    tokenizer = tokenize,\n",
    "    lowercase = True,\n",
    "    stop_words = 'english',\n",
    "    max_features = 85\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_matrix = vectorizer.fit_transform(Doc_reviews) \n",
    "#converting the reviews into feature vectors of fixed size using bag of words model approach. \n",
    "##Even better, if TfidfVectorizer() was used instead of CountVectorizer(), because it \n",
    "##would have downweighted words that occur frequently across docuemnts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting features Matrix to Pandas Dataframe to see the word frequencies.\n",
    "doc_term_matrix = features_matrix.todense()\n",
    "\n",
    "df = pd.DataFrame(doc_term_matrix, \n",
    "                  columns=count_vectorizer.get_feature_names())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Now, the team would like to search the reviews. Given a free-text string, called search_review, can you write another python script to compare the free-text string to all the review feature vectors in the database. The team would like to rank the comparisons and display the top three on the screen (python print)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a={'search_review': 'Excellent professional attitude that works across the whole company and is a pleasure to work with'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Excellent professional attitude that works across the whole company and is a pleasure to work with'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[\"search_review\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=[]\n",
    "\n",
    "#assumption: The search review is appended at the very end. This is just for demonstration, hence didn't write a function.\n",
    "#Ideally, the way data is given, depending on that a function will be written to append the data to documents array\n",
    "# Here, just for demonstration, the three documents are parsed from the json example given in the assignment\n",
    "\n",
    "doc1 = jsonData[0][\"recommendations\"][0]\n",
    "doc2= jsonData[0][\"recommendations\"][1]\n",
    "doc3= jsonData[0][\"recommendations\"][2]\n",
    "doc4= a[\"search_review\"]\n",
    "\n",
    "documents.append(doc1)\n",
    "documents.append(doc2)\n",
    "documents.append(doc3)\n",
    "documents.append(doc4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Donna is always on the ball, highly organised and a real pleasure to work with.',\n",
       " 'I have worked with Donna for a number of years and have always found her to be extremely professional and a real expert in her field.',\n",
       " 'I worked with Donna for 5 years and can highly recommend her as an experienced, knowledgeable. She is very hardworking designer with a meticulous eye for detail and creativity',\n",
       " 'Excellent professional attitude that works across the whole company and is a pleasure to work with']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.3\n"
     ]
    }
   ],
   "source": [
    "# importing the packages for the 2nd part of the assignment\n",
    "\n",
    "import gensim\n",
    "from gensim.matutils import softcossim \n",
    "from gensim import corpora\n",
    "import gensim.downloader as api\n",
    "from gensim.utils import simple_preprocess\n",
    "print(gensim.__version__)\n",
    "\n",
    "\n",
    "# Download the FastText model\n",
    "fasttext_model300 = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `similarity_matrix` (Method will be removed in 4.0.0, use gensim.models.keyedvectors.WordEmbeddingSimilarityIndex instead).\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I worked with Donna for 5 years and can highly recommend her as an experienced, knowledgeable. She is very hardworking designer with a meticulous eye for detail and creativity\n",
      "I have worked with Donna for a number of years and have always found her to be extremely professional and a real expert in her field.\n",
      "Donna is always on the ball, highly organised and a real pleasure to work with.\n",
      "Excellent professional attitude that works across the whole company and is a pleasure to work with\n"
     ]
    }
   ],
   "source": [
    "# Preparing a dictionary and a corpus.\n",
    "dictionary = corpora.Dictionary([simple_preprocess(doc) for doc in documents])\n",
    "\n",
    "# Preparing the similarity matrix\n",
    "similarity_matrix = fasttext_model300.similarity_matrix(dictionary, tfidf=None, threshold=0.0, exponent=2.0, nonzero_limit=100)\n",
    "\n",
    "# Convert the sentences i.e. reviews into bag-of-words vectors.\n",
    "\n",
    "def Vector_conversion(doc):\n",
    "    vect= dictionary.doc2bow(simple_preprocess(doc))\n",
    "    return vect\n",
    "\n",
    "Vectors=[]\n",
    "for i in documents:\n",
    "    Vectors.append(Vector_conversion(i))\n",
    "    print (i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity of new text with vector 0 is  0.4423087497953782\n",
      "Similarity of new text with vector 1 is  0.5040128735857902\n",
      "Similarity of new text with vector 2 is  0.6538491400382125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `softcossim` (Function will be removed in 4.0.0, use gensim.similarities.termsim.SparseTermSimilarityMatrix.inner_product instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `softcossim` (Function will be removed in 4.0.0, use gensim.similarities.termsim.SparseTermSimilarityMatrix.inner_product instead).\n",
      "  after removing the cwd from sys.path.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated `softcossim` (Function will be removed in 4.0.0, use gensim.similarities.termsim.SparseTermSimilarityMatrix.inner_product instead).\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "# Computing soft cosine similarity\n",
    "\n",
    "def similarity(vec1, vec2):\n",
    "    res= softcossim(vec1, vec2, similarity_matrix)\n",
    "    return res\n",
    "    \n",
    "leng= len(Vectors)\n",
    "dict1={}\n",
    "\n",
    "for i in range(0,leng-1):\n",
    "    sim=similarity(Vectors[leng-1], Vectors[i])\n",
    "    print (\"Similarity of new text with vector {} is \".format(i), sim)\n",
    "    data = {\"Similarity_with_Vector{}\".format(i) : sim}\n",
    "    dict1.update(data)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Similarity_with_Vector0': 0.4423087497953782,\n",
       " 'Similarity_with_Vector1': 0.5040128735857902,\n",
       " 'Similarity_with_Vector2': 0.6538491400382125}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity_with_Vector2 0.6538491400382125\n",
      "Similarity_with_Vector1 0.5040128735857902\n",
      "Similarity_with_Vector0 0.4423087497953782\n"
     ]
    }
   ],
   "source": [
    "#for sorting with respect to decresing order of similarity of the given string with other reviews \n",
    "# and giving the top three.\n",
    "\n",
    "sort_orders = sorted(dict1.items(), key=lambda x: x[1], reverse=True)[:3]\n",
    "\n",
    "for i in sort_orders:\n",
    "    print(i[0], i[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
